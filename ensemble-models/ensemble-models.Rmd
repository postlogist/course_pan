---
title: "Ensemble models"
author: "Gleb Zakhodyakin, postlogist@gmail.com"
date: '`r format(Sys.time(), "%d.%m.%Y")`'
output: 
  html_document: 
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Loading packages, message=FALSE, warning=FALSE}
library(MASS) #stepwise regression
library(mlr) # Machine Learning framework for R
library(stringr) # string processing
library(parallelMap) # Parallel computation
library(rpart.plot) # Visualization of rpart trees
library(ISLR) # Carseats dataset
library(tidyverse) # Data visualization and transformation
```


```{r}
data("Carseats")
Carseats <- 
  Carseats %>%
  filter(Sales > 0) #Filter out zero sales to prevent issues with computing MAPE

head(Carseats)

```


```{r}
Carseats %>%
  ggplot(aes(Advertising, Sales, color = ShelveLoc)) +
  geom_point() +
  geom_smooth(method = "lm", se = F)
```


```{r}
m_reg_full <- lm(Sales ~ ., data = Carseats)
m_reg_stepwise <- stepAIC(m_reg_full, direction = "both", trace = FALSE)
summary(m_reg_stepwise)
```





```{r}
tsk_Carseats <- makeRegrTask("Multiple Regression", data = Carseats, target = "Sales")
```


Baseline - multiple regression
```{r}
lrn_mlr <- makeLearner("regr.lm", id = "mlr")
```


Baseline - Lasso regression

```{r}
lrn_lasso <- makeLearner("regr.glmnet", id = "Lasso")
```



```{r}
rdesc_CV10 <- makeResampleDesc(method = "CV", 
                                   iter = 10)
```



```{r}
# A list of model performance metrics for regression
ms_regr = list(mape, timetrain, mae, rmse, rsq)
```



```{r}
# Setting the random number generator for reproducibility
set.seed(123, "L'Ecuyer")

# Detecting the number of avaliable CPU cores
num_cores <- parallel::detectCores()

# Starting parallelization
parallelStartSocket(num_cores)

bench_Carseats_baseline <-  
  tsk_Carseats %>%
  benchmark(learners = list(lrn_mlr, lrn_lasso),
            tasks = .,
            resampling = rdesc_CV10,
          measures = ms_regr,
         show.info = TRUE)

parallelStop()

```



```{r}
printBenchmark <- function(benchmarkResults) {
  benchmarkResults %>%
  getBMRAggrPerformances(as.df = TRUE) %>%
  arrange(mape.test.mean) %>%
  dplyr::select(-task.id) %>%
  mutate_if(is.numeric, round, digits = 3)
}
```


```{r}
bench_Carseats_baseline %>%
  printBenchmark()
```


Tree-based learners
```{r}
lrn_rpart <- makeLearner("regr.rpart", id = "rpart")
lrn_ctree <- makeLearner("regr.ctree", id = "ctree")
```



```{r}
# Setting the random number generator for reproducibility
set.seed(123, "L'Ecuyer")

# Starting parallelization
parallelStartSocket(num_cores)

bench_Carseats_trees <-  
  tsk_Carseats %>%
  benchmark(learners = list(lrn_rpart, lrn_ctree),
            tasks = .,
            resampling = rdesc_CV10,
          measures = ms_regr,
         show.info = TRUE)

parallelStop()

```

```{r}
bench_Carseats_trees %>%
  printBenchmark()
```


Bagging

```{r}

tsk_Carseats %>% createDummyFeatures()

lrn_rf <- makeLearner("regr.randomForest", id="Random Forest", mtry = 4, ntree = 50)

lrn_bagging <- makeLearner("regr.randomForest", id="Bagging (via RF)", mtry = 20, ntree = 50)
lrn_ranger <- makeLearner("regr.ranger", id="ranger", mtry = 4, num.trees = 50)


```

```{r}
lrn_gbm <- makeLearner("regr.gbm", id="gbm", n.trees = 100)

lrn_gbm %>% getLearnerParamSet()
```

```{r}
lrn_xgboost <- makeLearner("regr.xgboost", id="xgboost", nrounds = 100)
#lrn_xgboost %>% getLearnerParamSet()
```


```{r}
# Setting the random number generator for reproducibility
set.seed(123, "L'Ecuyer")

# Starting parallelization
parallelStartSocket(num_cores)

bench_Carseats_ensembles <-  
  tsk_Carseats %>%
  createDummyFeatures() %>% # xgboost doesn't support factors
  benchmark(learners = list(lrn_bagging, lrn_rf, lrn_ranger, lrn_gbm, lrn_xgboost),
            tasks = .,
            resampling = rdesc_CV10,
          measures = ms_regr,
         show.info = TRUE)

parallelStop()

bench_Carseats_ensembles %>%
  printBenchmark()

```

```{r}
lrn_xgboost %>%
  getLearnerParamSet()
```


tune xgboost
```{r}
set.seed(123, "L'Ecuyer")
lrn_xgb_tune <- makeLearner("regr.xgboost")

rdesc_CV5 <- makeResampleDesc(method = "CV", 
                                   iter = 5)

ps_xgb <- makeParamSet(
         #makeDiscreteParam("booster",values = c("gbtree","gblinear", "dart")),
         makeIntegerParam("max_depth",lower = 1L,upper = 10L),
         makeIntegerParam("nrounds",lower = 1L,upper = 200L),
         makeNumericParam("min_child_weight",lower = 1L,upper = 10L),
         makeNumericParam("subsample",lower = 0.5,upper = 1),
         makeNumericParam("colsample_bytree",lower = 0.5,upper = 1),  
         makeNumericParam("lambda",lower = -1,upper = 2, trafo = function(x){10^x}),
         makeNumericParam("eta",lower = 0.1,upper = 0.5)
         
)

ctrl <- makeTuneControlGenSA(budget = 50, maxit = 50, max.time = 300)

parallelStart()

Carseats_xgb_tune <- 
  tuneParams(
    learner = lrn_xgb_tune,
    task = createDummyFeatures(tsk_Carseats),
    resampling = rdesc_CV5,
    measures = mape,
    par.set = ps_xgb,
    control = ctrl,
    show.info = T
  )

parallelStop()
```




Quadratic data

```{r}
set.seed(123)

true_f <- function(x) {
  (x - 10)^2
}

quadratic <- 
  tibble(
    x = seq(0, 20, by = 0.01)
  ) %>%
  mutate(
    y =  true_f(x)+ rnorm(2001, sd = 5)
  )

ggplot(quadratic, aes(x, y)) +
  geom_point(alpha = 0.1) +
  geom_smooth() +
  stat_function(fun = true_f, color = 'red')
```




```{r}
tsk_quadratic <- makeRegrTask(id = "Quadratic Function", 
                              data = quadratic,
                              target = "y")

tsk_quadratic_poly <- quadratic %>%
  mutate(x2 = x^2) %>%
  makeRegrTask(id = "Quadratic Function with Polynomial terms", 
                              data = .,
                              target = "y")
  
```


```{r}
# Setting the random number generator for reproducibility
set.seed(123, "L'Ecuyer")

# Starting parallelization
parallelStartSocket(num_cores)

bench_quadratic_baseline <-  
  tsk_quadratic_poly %>%
  benchmark(learners = list(lrn_mlr, lrn_lasso),
            tasks = .,
            resampling = rdesc_CV10,
          measures = ms_regr,
         show.info = TRUE)

parallelStop()

```


```{r}
bench_quadratic_baseline %>%
  printBenchmark()
```


```{r}
lrn_mlr %>%
  train(learner = ., 
        task = tsk_quadratic_poly) %>%
  predict(tsk_quadratic_poly) %>%
  as.data.frame() %>%
  cbind(quadratic) %>%
  ggplot(aes(x)) +
  geom_point(aes(y = truth), alpha = 0.1) +
  stat_function(fun = true_f, color = 'blue') +
  geom_line(aes(y = response), color = 'red')

```


```{r}
lrn_lasso %>%
  train(learner = ., 
        task = tsk_quadratic_poly) %>%
  predict(tsk_quadratic_poly) %>%
  as.data.frame() %>%
  cbind(quadratic) %>%
  ggplot(aes(x)) +
  geom_point(aes(y = truth), alpha = 0.1) +
  stat_function(fun = true_f, color = 'blue') +
  geom_line(aes(y = response), color = 'red')
```

```{r}
makeLearner("regr.rpart", minsplit = 8, cp = 0.001) %>%
  train(learner = ., 
        task = tsk_quadratic) %>%
  predict(tsk_quadratic) %>%
  as.data.frame() %>%
  cbind(quadratic) %>%
  ggplot(aes(x)) +
  geom_point(aes(y = truth), alpha = 0.1) +
  stat_function(fun = true_f, color = 'blue') +
  geom_line(aes(y = response), color = 'red')

```

```{r}
lrn_ctree %>% getLearnerParamSet()
```


```{r}
lrn_ctree %>%
  train(learner = ., 
        task = tsk_quadratic) %>%
  predict(tsk_quadratic) %>%
  as.data.frame() %>%
  cbind(quadratic) %>%
  ggplot(aes(x)) +
  geom_point(aes(y = truth), alpha = 0.1) +
  stat_function(fun = true_f, color = 'blue') +
  geom_line(aes(y = response), color = 'red')


```



```{r}
lrn_bagging %>%
  
  train(learner = ., 
        task = tsk_quadratic_poly) %>%
  predict(tsk_quadratic_poly) %>%
  as.data.frame() %>%
  cbind(quadratic) %>%
  ggplot(aes(x)) +
  geom_point(aes(y = truth), alpha = 0.1) +
  stat_function(fun = true_f, color = 'blue') +
  geom_line(aes(y = response), color = 'red')

```


```{r}
makeLearner("regr.randomForest", id="Random Forest", ntree = 20, nodesize = 150) %>%
  train(learner = ., 
        task = tsk_quadratic) %>%
  predict(tsk_quadratic) %>%
  as.data.frame() %>%
  cbind(quadratic) %>%
  ggplot(aes(x)) +
  geom_point(aes(y = truth), alpha = 0.1) +
  stat_function(fun = true_f, color = 'blue') +
  geom_path(aes(y = response), color = 'red')

```

```{r}
lrn_xgboost %>%
  getLearnerParamSet()
```


```{r}
makeLearner("regr.xgboost", 
            nrounds = 40, eta = 0.1) %>%
  train(learner = ., 
        task = tsk_quadratic) %>%
  predict(tsk_quadratic) %>%
  as.data.frame() %>%
  cbind(quadratic) %>%
  ggplot(aes(x)) +
  geom_point(aes(y = truth), alpha = 0.1) +
  stat_function(fun = true_f, color = 'blue') +
  geom_line(aes(y = response), color = 'red')


```

```{r}
lrn_gbm %>% getLearnerParamSet()
```


```{r}
makeLearner("regr.gbm", 
            n.trees = 500,
            shrinkage = 0.1) %>%
  train(learner = ., 
        task = tsk_quadratic) %>%
  predict(tsk_quadratic) %>%
  as.data.frame() %>%
  cbind(quadratic) %>%
  ggplot(aes(x)) +
  geom_point(aes(y = truth), alpha = 0.1) +
  stat_function(fun = true_f, color = 'blue') +
  geom_line(aes(y = response), color = 'red')



```
