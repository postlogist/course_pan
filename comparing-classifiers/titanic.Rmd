---
title: "Building and comparing classification models"
author: "Gleb Zakhodyakin"
date: '23.09.2019'
output: 
  html_document: 
    toc: yes
    toc_float: yes
---

# Introduction

This notebook provides a tutorial on solving a classification task using logistic regression and decision tree algorithms. Here we build and compare a few models trying to predict the survival of Titanic passengers. 


# Preparation

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits = 3) # Setting the output precision to 3 decimals
```


```{r, warning=FALSE, message=FALSE}
library(tidyverse) # Data transformation and visualization
library(scales) # Enables percentage scale for ggplot graphs
library(rpart) # Decision Trees: the CART algorithm
library(C50) # Another implementation of decision trees in R: C5.0
library(party) # Another tree-based algorithm: conditional inference trees
library(rpart.plot) # Nice visualization of rpart Decision Trees
library(partykit) # Visualization of Conditional Inference and C5.0 Trees
library(mlr) # MAchine learning framework for R. Here we are using model accuracy metrics provided by the package.
library(ROCR) # Plotting ROC
library(RColorBrewer) # Good color scales

```

The data are in `titanic.csv` file.

```{r, message=FALSE}
d <- read_csv("titanic.csv")
glimpse(d)
```

The dataset contains information on  `r nrow(d)` passengers.

Variables:
 - `survived` - the target (survived or not)
 - `pclass` - passenger class (first, second or third)
 - `sex` - gender
 - `age` - age, years
 - `sibsp` - the number of accompanying relatives - brothers, sisters or spouses
 - `parch` - the number of accompanying children or parents
 - `fare` - ticket price paid by the passenger

The variables `sibsp`, `parch`, `age` and `fare` are quantitative, the rest are categorical. From the summary above we can see, that the categorical variables are stored now as a text.

# The exploratory data analysis

## Data Preparation

Let's consider  distributions of variables and the presence of missing values.

```{r}
summary(d)
```

Variables `age` and `fare` contain NAs. The fare is unknown just for one passenger, but age is not provided for more than 260 passengers, orabout 20% of observations. This is a significant proportion of data, so we must decide on the strategy for replacing NAs in the `age` variable for the modeling purpose.

We must also convert the text variables into factors. It is a good idea to set the factor levels manually, otherwise the alphabetical ordering of factor levels will be used.

Let's also convert the target variable into a factor:

```{r}
d <- d %>% 
  mutate(survived = as.factor(survived))
```

The levels will be in the alphabetical order - `died`, `survived`. The last level (`survived`) will be considered a 'positive' outcome.

## Factors influencing the survival probability

Let's explore, how the survival probability correlates with different factors

### Passenger class

```{r}
ggplot(d) +
  geom_bar(aes(x = pclass, fill = survived), position = "fill") +
  scale_y_continuous(labels = percent) +
  labs(title = "Survival Probability vs Passenger Class",
       x = "Passenger class", y = NULL, fill = NULL)
```

The survival probability is correlated with the passenger class. The 1st class passengers have mostly survived, the 3rd class passengers had just a 25% of survival.

### Gender

```{r}
ggplot(d) + 
  geom_bar(aes(x = sex, fill = survived), position = "fill") +
  scale_y_continuous(labels = percent) +
  labs(title = "Survival Probability vs Gender",
       x = "Gender", y = NULL, fill = NULL)
```

The proportion of survived males is significantly lower.

Let's bring more factors into consideration and see, if the survival probability is dependent both on gender and the passenger class.

```{r}
ggplot(d) + 
  geom_bar(aes(x = sex, fill = survived), position = "fill") +
  facet_wrap(~ pclass) + 
  scale_y_continuous(labels = percent) +
  labs(title = "Survival probability vs Gender and Class",
       x = "Gender", y = NULL, fill = NULL)
```

Here we can see the interaction between gender and passenger class: almost all women among 1st class passengers have survived. But in the 3rd class the proportion of survived women is much lower. Such an interaction between variables should be incorporated into a model.


### Age

Let's see, how the survival probability depends on age of the passenger. To simplify visualization, we'll split all passengers into a few age groups.

```{r, fig.height=5, fig.width=10}
ggplot(d) + 
  geom_bar(aes(x = cut(age, breaks = seq(0, 80, by = 5), right = TRUE),
               fill = survived), position = "fill") +
  scale_y_continuous(labels = percent) +
  labs(title = "Survival probability vs Age",
       x = "Age of a Passenger", y = NULL, fill = NULL)
```

Here we observe that the relationship is non-linear. Small children under 5 years and very old people aged 75 or more have larger survival proportion. Despite this, all passengers aged between 654 and 75 years have died. We can also see a separate group of passengers with an unknown age.

It's important to know, how reliable are such estimates of the survival rate. To answer this question, we can plot the size of each age group.


```{r}
ggplot(na.omit(d)) + 
  geom_histogram(aes(x = age, fill = survived), bins = 40) +
  labs(title = "The number of passengers in each age group",
       x = "Age", y = "Number of Passengers", fill = NULL)
```

Here we can see, that the number of elder passengers is quite small, so we won't care much about the peak of survival probability for the 75-80 years group.

Now, let's consider if the relationship between age and survival is the same for different passenger classes.


```{r, fig.height=7, fig.width=10}
ggplot(d) + 
  geom_bar(aes(x = cut(age, breaks = seq(0, 80, by = 5), right = TRUE),
               fill = survived), position = "fill") + 
  facet_wrap(~pclass, ncol = 1) +
  scale_y_continuous(labels = percent) +
  labs(title = "Survival Probability vs Age and Class",
       x = "Age of a Passenger", y = NULL, fill = NULL)  

```

We can see, that in the 1st class almost all children under 15 have survived, and most seniors above 50 have died. Again, this trend is different between the classes.
This should be accounted for while modeling. In a logistic regression model each predictor contributes linearly to the outcome. In case of age, the probability of survival should be proportional to age. To model the non-linear relationship between age and survival we've just discovered, we can **discretize** the predictor variable. This will allow a non-proportional contribution for different age groups.


```{r, fig.height=5, fig.width=10}
d <- d %>%
  mutate(agef = cut(age, 
                    breaks = c(0, 15, 50, 85),
                    labels = c("child", "adult", "senior"),
                    right = FALSE)) %>%
  mutate(agef = fct_explicit_na(agef, na_level = "unknown"))

ggplot(d) + 
  geom_bar(aes(x = agef,
               fill = survived), position = "fill") +
  facet_wrap(~pclass) +
  scale_y_continuous(labels = percent) +
  labs(title = "Probability of Survival vs Age and Class",
       x = "Age Group", y = NULL, fill = NULL)  

```

Since the relationship is different for different passenger classes, an interaction between factors should be incorporated into the model.

### Companions - siblings and spouses

Let's see, how the presence of companions is correlated to survival. Here we discretize the `sibsp` variable to ensure that the bars on the plot take only integer steps.

```{r}
ggplot(d) + 
  geom_bar(aes(x = factor(sibsp),
               fill = survived), position = "fill") +
  scale_y_continuous(labels = percent) +
  labs(title = "Survival Probability vs Siblings & Spouses",
       x = "Number of siblings and spouses", y = NULL, fill = NULL)  
  
```

The best chances for survival have the passengers with one or two companions. All members of very large groups have died.

Now, we consider, if this relationship depends on the class.


```{r}

ggplot(d) + 
  geom_bar(aes(x = factor(sibsp),
               fill = survived), position = "fill") + 
  facet_wrap(~pclass, ncol = 1) + 
  scale_y_continuous(labels = percent) +
  labs(title = "Survival probability vs Siblings, Spouses and Class",
       x = "Number of Siblings, Spouses Class", y = NULL, fill = NULL)  

```

The relationship differs slightly for different classes. Within the 3rd class the chances to survive were the best for passengers with one companion. The chances for lerger groups were better in the 1st and the 2nd classes.

To accomodate the non-linear relationship, we'll again discretize the number of companions into the following groups: single passengers, small groups (1-2 companions), large groups (3+ companions).


```{r, fig.height=5, fig.width=10}
d <- d %>%
  mutate(sibspf = cut(sibsp, 
                      breaks = c(0, 1, 3, 9),
                      labels = c("single", "small","large"),
                      right = FALSE))


ggplot(d) + 
  geom_bar(aes(x = sibspf,
               fill = survived), position = "fill") +
  facet_wrap(~pclass) +
  scale_y_continuous(labels = percent) +
  labs(title = "Survival Probabiilty vs Siblings, Spouses and Class",
       x = "Group Size", y = NULL, fill = NULL)  

```

### Companions - children and parents

We'll treat accompanying children and parents in a similar way.

Survival probability vs the number of companions:

```{r}
ggplot(d) + 
  geom_bar(aes(x = factor(parch),
               fill = survived), position = "fill") +
  scale_y_continuous(labels = percent) +
  labs(title = "Survival Probability vs Number of Parents and Children",
       x = "Number of Parents and Children", y = NULL, fill = NULL)  
```

By class:

```{r}
ggplot(d) + 
  geom_bar(aes(x = factor(parch),
               fill = survived), position = "fill") +
  facet_wrap(~pclass, ncol = 1) +
  scale_y_continuous(labels = percent) +
  labs(title = "Survival Probability vs Number of Parents, Children and Class",
       x = "Number of Parents and Children", y = NULL, fill = NULL)  
```

The relationship is similar to the one for siblings and spouses: single passengers and large groups have the least chances to survive. Travelling in a small group does increase the probability to survive.

Let's discretize groups using the same thresholds, as above:


```{r, fig.height=5, fig.width=10}

d <- d %>%
  mutate(parchf = cut(parch, 
                      breaks = c(0, 1, 3, 10),
                      labels = c("single", "small", "large"),
                      right = FALSE))


ggplot(d) + 
  geom_bar(aes(x = parchf,
               fill = survived), position = "fill") +
  facet_wrap(~pclass) +
  scale_y_continuous(labels = percent) +
  labs(title = "Survival Probability vs Number of Children, Parents and Class",
       x = "Number of Children and Parents", y = NULL, fill = NULL)  

```


### The Fare

Now let's see, if the fare paid is correlated to the survival probability

```{r}
ggplot(na.omit(d)) + 
  geom_histogram(aes(x = fare, fill = survived), position = "fill", bins = 20) +
  facet_wrap(~pclass, ncol = 1) +
  scale_y_continuous(labels = percent) +
  labs(title = "Survival Probability vs Fare",
       x = "Fare", y = NULL, fill = NULL)   

```

The relationship is prominent only for the 1st and 2nd class passengers. It seems that only for these classes the fare paid by the passenger determined the location of his/her cabin, and the survival probability as a result. In the 3rd class, the probability was equally low for everyone regardless the fare.

Let's see, if there's a missed influence from gender or age.

```{r}
ggplot(na.omit(d)) +
  geom_jitter(aes(age, fare, colour = survived)) +
  facet_grid( pclass ~ sex, scale = "free_y")
```

There's no difference in fares by gender. The age is correlated to the fare. For example, we can see, that for children below 15 the parents didn't buy the cheapest tickets. The cheapest fares were paid by adults in the 2nd and the 3rd class. This category faced the lowest survival probability. This fact might explain the increase in survival probability for higher fares.



# Modeling


## Train-test split

To estimate the predictive accuracy of our model, we'll test it on the new data. For this, we'll split the dataset into the training and the testing samples.

```{r}
set.seed(12) # Setting the random seed for reproducibility
train_ind <- sample(nrow(d), 900)
d_train <- d[train_ind, ] # Training sample
d_test <- d[-train_ind, ] # Test sample
```

## Logistic Regression with gender and class only

As a first step, we'll build a logistic regression model using the two most important predictors - the gender and the class of a passenger. We'll also include the interaction of these two factors, as we've seen the different effect of gender for different classes:

```{r}
m_lr_sexclass <- glm(survived ~ pclass + sex + pclass : sex, 
                     data = d_train,
                     family = binomial(link = "logit"))
summary(m_lr_sexclass)
```

### Interpreting the coefficients


Коэффициенты в модели логистической регрессии - это изменение логита, т.е. логарифма шансов при единичном изменении предиктора. В нашей модели все предикторы - это фиктивные переменные, поэтому коэффициенты регрессии показывают отличия в шансах на выживание для соответствующих групп.

Т.к. мы включили пол и класс в модель, коэффициенты позволяют сравнить шансы пассажиров одного и того же пола в разных классах. Или сравнить шансы женщин и мужчин, следовавших одним классом.

Базовой категорией по классу является первый класс. Во втором классе шансы выжить ниже (однако отличие статистически не значимо). В третьем - существенно ниже.

Базовой категорией по полу является женщина. Для мужчин шансы выжить существенно ниже.

Однако, ситуация неодинакова в различных классах. Например, если расмотреть 2 класс, то шансы на выживание мужчин в нем незначительно ниже, а в третьем классе - существенно выше, чем для мужчин в первом классе.

В качестве примера, рассчитаем прогозы.

 - Шансы выжить для женщины из 1 класса: $O = \exp(2.955) = 19.2$  
 Это соответствует вероятности выживания: $P = 19.2 / (19.2 + 1) = 0.95$

 - Шансы выжить для мужчины из 1 класса: $O = \exp(2.955 - 3.409) = 0.635$   
 Вероятность выжить: $P = 0.635 / 1.635 = 0.388$

 - Шансы выжить для мужчины из 2 класса: $O = \exp(2.955 - 0.957 - 3.409 - 0.220) = 0.196$   
 Вероятность выжить: $P = 0.196 / 1.196 = 0.164$

- Шансы выжить для мужчины из 3 класса: $O = \exp(2.955 - 2.916 - 3.409 + 1.717) = 0.191$  
Вероятность выжить: $P = 0.191 / 1.191 = 0.160$

Коэффициенты логистической регрессии, как уже упоминалось, представляют собой изменение логарифма шансов при единичном значении предиктора. Учитывая, что $\ln a - \ln b = \ln a/b$, можно рассматривать угловой коэффициент как логарифм отношения шансов при единичном измении предиктора (0 - нет изменения). Удобнее сравнивать не логарифм, а  само отношение, поэтому можно преобразовать коэффициенты:

```{r}
coefficients(m_lr_sexclass) %>% exp()
```

Теперь сразу видно, что для базовой категории шансы выживания - 19.2, для мужчины из 1 класса шансы выжить ниже (19.2 * 0.0331 = 0.636) и т.д. 

Отношение шансов = 1 означает отсутствие изменения шансов.

В тех случаях, когда результаты исследования получены с помощью случайной выборки и их требуется обобщить на генеральную совокупность, можно воспользоваться расчетом доверительных интервалов для коэффициентов регрессии:

```{r}
confint(m_lr_sexclass) %>% exp()
```

Однако в нашем случае проверка значимости коэффициентов не имеет смысла, т.к. исходные данные не являются случайной выборкой и их не на что обобщить. Тем не менее, можно ориентироваться на показатели значимости, чтобы оценить точность оценки коэффициентов (т.е. сопоставить величину эффекта для группы с ошибкой оценки этого эффекта).


### Альтернативный способ интерпретации модели

Вместо того, чтобы интерпретировать отдельные коэффициенты, можно сделать прогноз по модели для типичных представителей разных категорий и сравить вероятности выживания.

```{r}
nd <- tribble(
  ~pclass, ~sex,
  "1st",   "female",
  "1st",   "male",
  "2nd",   "female",
  "2nd",   "male",
  "3rd",   "female",
  "3rd",   "male"
  )

cbind(nd, prob_survive = predict(m_lr_sexclass, newdata = nd, type = "response"))

```

**Важно:**  поскольку в модели используются факторные переменные, важно чтобы в наборе данных для прогнозирования уровни фактора были такими же, и в том же порядке, что и в наборе, по которому строилась модель. Здесь это достигается благодаря тому, что мы рассмотрели все значения каждого фактора. 


## Логистическая регрессия с сочетанием всех факторов

Теперь построим более сложную регрессию с большим количеством факторов - добавим возрастную категорию и число сопровождающих. Т.к. мы видели, что эти зависимости различные по классам пассажиров, добавим также взаимодействие класса со всеми этими факторами.

```{r}
m_lr_all <- glm(survived ~ (sex + agef + sibspf + parchf + sex) * pclass, 
                data = d_train,
                family = binomial(link = "logit"))
summary(m_lr_all)
```

Модель получилась довольно сложная. Из-за большого числа предикторов увеличились стандартные ошибки оценки коэффициентов, поэтому большинство переменных оказалось незначимыми. Также мы можем наблюдать линейную зависимость между включенными в модель переменными. Один из столбцов - эффект взаимодействия факторов 2 класс и большая группа - был исключен.

## Логистическая регрессия - упрощенная модель 

Попробуем упростить модель, используя метод пошагового исключения переменных. Для выбора лучшей модели функция использует критерий AIC.

```{r}
m_lr_step <- step(m_lr_all)
```

Окончательная модель имеет вид:

```{r}
summary(m_lr_step)
```

В упрощенной модели остались главные эффекты всех факторов. Эффекты взаимодействия учитываются только для пола и класса.

## Дерево решений - rpart

Задачу классификации можно решать и с помощью деревьев решений. Пакет `rpart` в R реализует алгоритм построения деревьев решений CART. 

В отличие от логистической регрессии, деревья решений - локальная модель. Благодаря разделению пространства предикторов на независимые части, внутри которых зависимости могут быть никак не связаны с зависимостями в других частях, для деревьев решений не представляют проблемы нелинейные зависимости, которые мы могли наблюдать в данных: например, что дети и пожилые люди имеют больше шансов выжить, чем люди среднего возраста. В логистической регрессии такие зависимости нужно линеаризовать. В деревьях решений мы можем работать с исходными количественными данными. 

Также алгоритм может работать с пропущенными значениями. Если встречается такое значение в  выбранной для разбиения переменной, то наблюдение классифицируется по другим признакам (surrogate split). Однако имеет смысл пробовать исправлять проблему пропущенных значений явно (например, путем подстановки средних, фиктивных значений или категоризации). Это может улучшить качество модели в некоторых случаях.

```{r}
m_rpart <- rpart(survived ~ pclass + sex + sibsp + parch + age,
                 data = d_train)
rpart.plot(m_rpart)

```

Алгоритм использует различные критерии для предотвращения чрезмерного "разрастания" дерева решения. В данном случае оно получилось довольно "куцым". 

Наиболее важной переменной является пол: по ней проведено разбиение в первую очередь. Дерево, фактически, предсказывает гибель всем мужчинам старше 9 лет. 

Для женщин принятие решения несколько сложнее - учитывается также класс, количество сопровождающих и возраст.  Пороги для разбиения по возрасту несколько отличаются от тех, которые мы подобрали визуальным способом: для детей - 9 лет, для взрослых - 24 года. По числу сопровождающих порог такой же, как и в регрессионной модели, правда он один.

Чистота листьев дерева невысокая. Например, в первом слева листе лишь 80% попавших туда пассажиров в действительности погибли, а в соседнем листе действительно выживших - только 70%. 
В качестве упражненения попытайтесь увеличить "разборчивость" модели, изменяя параметры остановки алгоритма - по числу узлов, числу примеров в узле и параметру сложности `cp`. 
Про это можно почитать в справке - см. `?rpart` и `?rpart.control`.


## Дерево решений - ctree

Попробуем применить другой алгоритм построения дерева решений - conditional inference tree (пакет `party`).

```{r, fig.height=7, fig.width=12}
m_ctree <- ctree(survived ~ factor(pclass) + factor(sex) + age + sibsp + parch,
                 data = d_train)
plot(m_ctree)
```

Построенное дерево несколько более симметрично, чем в случае `rpart`, однако оно тоже небольшое и с "грязными" листьями.

## Дерево решений - C5.0

Попробуем применить еще один алгоритм построения дерева решений - C5.0. Поскольку процедура визуализации дерева не очень хорошо работает с текстовыми переменными, мы выведем структуру построенного дерева в текстовом виде.

```{r}
m_c50 <- C5.0(survived ~ pclass + sex + age + sibsp + parch,
                 data = d_train)
summary(m_c50)
```

Построенное дерево очень похоже на дерево, построенное `rpart`. Отличие состоит только в ветви для классификации женщин-пассажиров 3 класса. Вместо возраста используется число сопровождающих детей и родителей.

Дополнительно построим еще одну модель с помощью этого алгоритма - на этот раз, с использованием бустинга. Судьба пассажира будет прогнозироваться ансамблем из 20 деревьев решений.

```{r}
m_c50_boost <- C5.0(survived ~ pclass + sex + age + sibsp + parch,
                 data = d_train, trials = 20)
summary(m_c50_boost)
```

Было построено 20 моделей. Первоначальную ошибку классификации модели удалось снизить с 19.9% только до 19.3%.


# Сравнение моделей

## Методы оценки качества моделей классификации

Оценить точность классификации можно путем сравнения предсказанных моделью меток классов с фактическими. Только сравнение результатов **на тестовом наборе** данных дает объективную оценку предсказательной силы модели. Использование обучающей выборки для оценки ошибки модели дает чрезмерно оптистичный результат, поскольку многие модели склонны к переобучению.

Рассмотрим различные методы оценки точности классификатора на примере логистической регрессии с двумя факторами.

### Интерпретация матрицы ошибок классификации и показателей точности

Поскольку модель логистической регрессии предсказывает не исход, а вероятность исхода, который считается положительным, необходимо преобразовать вероятность в метку класса путем сравнения с некоторым порогом. Для начала используем порог в 50%

```{r}
# Прогноз вероятности выживания
pr_lr_sexclass <- predict(m_lr_sexclass, newdata = d_test, type = "response")

# Прогноз исхода для пассажира
cat("Порог 0.5:\n")
cl_lr_sexclass <- ifelse(pr_lr_sexclass > 0.5, "survived", "died")

# Матрица ошибок классификации (confusion matrix)
table(predicted = cl_lr_sexclass, actual = d_test$survived)

```

Элементами матрицы ошибок классификации являются:

 - $TN = 224$ - истинноотрицательные примеры (предсказана смерть, умер)
 
 - $TP = 106$ - истинноположительные примеры (предсказано спасение, спасся)
 
 - $FP = 39$ - ложноположительные примеры (предсказано спасение, умер)
 
 - $FN = 40$ - ложноотрицательные примеры (предсказана смерть, спасся)
 
 
Всего в тестовой выборке 409 пассажиров

Используя эту матрицу, можно рассчитать [**показатели ошибки модели**](https://en.wikipedia.org/wiki/Sensitivity_and_specificity):

**Средняя точность** (accuracy) - доля правильно классифицированных примеров:


$$ ACC = \frac{TP  + TN}{TP + TN + FP + FN} = \frac{224+106}{409} = 80.7\% $$
Этот показатель характеризует, как часто модель угадывает правильный ответ.


**Средняя ошибка классификации** (overall error rate, mean misclassification error) - доля ошибочно классифицированных примеров:


$$ MMCE = \frac{FP  + FN}{TP + TN + FP + FN} = \frac{39+40}{409} = 19.3\% $$
Этот показатель характеризует, как часто модель ошибается.

**Чувствительность** (sensitivity, true positive rate, recall) - доля положительных примеров, которые были правильно классифицированы как положительные:

$$ TPR =  \frac{TP}{P} = \frac{TP}{TP + FN} = \frac{106}{106 + 40} = 72.6\% $$
Этот показатель характеризует чувствительность модели при обнаружении положительных примеров. Модель с низкой чувствительностью позволит выявить лишь небольшую часть положительных примеров в данных. Модель с высокой чувствительностью выявит большую часть таких примеров.


**Специфичность** (specificity, true negative rate) - доля отрицательных примеров, которые были правильно классифицированы как отрицательные:

$$ TNR =  \frac{TN}{N} = \frac{TN}{TN + FP} = \frac{224}{224 + 39} = 85.2\% $$
Этот показатель аналогичен чувствительности, но здесь интерес представляют отрицательные примеры, а не положительные.


**Доля ложных срабатываний** (false positive rate, fall-out) - доля неправильно классифицированных отрицательных примеров:

$$ FPR =  \frac{FN}{N} = \frac{FP}{TN + FP} = \frac{39}{224 + 39} = 14.8\% $$
Этот показатель характеризует, какая доля отрицательных примеров будет ошибочно классифицирована как положительные. Если рассмотреть задачу классификации почты на полезную и спам, то "ложным срабатыванием" модели будет попадание полезного письма в спам ("положительным", т.е. интересным классом здесь будет спам, номальные письма будут "отрицательным" классом). Доля ложных срабатываний в данном случае будет долей полезных писем, попавших в спам.

Можно видеть, что $FPR = 1 - TNR$, т.е. 1 - специфичность.


**Точность** (precision, positive predictive value) - надежность классификации положительных примеров, т.е. доля классифицированных как положительные примеров, которые действительно являются положительными

$$ PPV =  \frac{TP}{TP + FP} = \frac{106}{106 + 39} = 73.1\% $$
Возвращаясь к примеру с фильтрацией спама, точность классификатора можно оценить как долю действительно спамерских писем в папке "Спам".

Для удобства расчета показателей ошибки, создадим функцию. На вход ее нужно подать векторы с прогнозными и фактическими метками класса, метки положительного и отрицательного класса. Также можно подать вектор с вероятностями положительного исхода. Вычисление показателей выполняется с помощью функций пакета `mlr`.

```{r}

# Функция для расчета показателей ошибки
perf <- function(predicted, actual, positive, negative,
                 probabilities = NULL ) {
  p <- 
    c(
      Accuracy = measureACC(actual, predicted),
      kappa = measureKAPPA(actual, predicted),
      TPR = measureTPR(actual, predicted, positive = positive),
      TNR = measureTNR(actual, predicted, negative = negative),
      FPR = measureFPR(actual, predicted, negative = negative, positive = positive),      
      PPV = measurePPV(actual, predicted, positive = positive)
  )
  
  if (!is.null(probabilities)) {
    p <- c(p, AUC = measureAUC(probabilities = probabilities, 
                               truth = actual, 
                               negative = negative,
                               positive = positive))
  }
  p
}

```


Выведем еще раз таблицу с ошибками классификации для двухфакторной регрессионной модели и посчитаем показатели эффективности. 

```{r}
# Прогноз исхода для пассажира
cat("Порог 0.5:\n")
cl_lr_sexclass <- ifelse(pr_lr_sexclass > 0.5, "survived", "died")

# Матрица ошибок классификации (confusion matrix)
table(predicted = cl_lr_sexclass, actual = d_test$survived)
perf(cl_lr_sexclass, d_test$survived, positive = "survived", negative = "died") * 100
```


### Зависимость показателей ошибки от порога классификации

Мы произвольным образом выбрали порог по вероятности положительного исхода, предсказанной моделью. Если предсказанная вероятность выживания превысит 50%, то пассажир будет классифицирован как выживший. Однако порог можно менять. Так, если нужно правильно классифицировать больше выживших в реальности пассажиров, то порог можно снизить. Тогда классификатор будет относить к выжившим большее количество пассажиров и число верно "угаданных" выживших увеличится. Однако увеличится и число "ложных срабатываний". 

Наоборот, если нежелательно, чтобы модель предскзывала выживание пассажирам, которые в действительности погибли, то можно снизить порог. Но неизбежно сократится и число верно "угаданных" выживших, т.е. чувствительность модели.

Сравним результаты при разных значениях порога классификации:

```{r}

cat("Порог 0.8:\n")
cl_lr_sexclass_80 <- ifelse(pr_lr_sexclass > 0.8, "survived", "died")
table(predicted = cl_lr_sexclass_80, actual = d_test$survived)
perf(cl_lr_sexclass_80, d_test$survived, positive = "survived", negative = "died") * 100

cat("\nПорог 0.30:\n")
cl_lr_sexclass_30 <- ifelse(pr_lr_sexclass > 0.3, "survived", "died")
table(predicted = cl_lr_sexclass_30, actual = d_test$survived)
perf(cl_lr_sexclass_30, d_test$survived, positive = "survived", negative = "died") * 100


```


### ROC-анализ

Компромисс между чувствительностью модели (TPR) и долей ложных срабатываний (FPR), можно отобразить в с помощью ROC-кривой (Receiver Operating Curve).

```{r}

performance_lr_sexclass <-  
  prediction(pr_lr_sexclass, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")

plot(performance_lr_sexclass, colorize = TRUE,
     main = "ROC для логрегрессии с факторами: пол и класс")

```

На графике видно, что с увеличением порога классификации снижается доля ложных срабатываний, но и чувствительность тоже падает. 

Здесь показан характерный вид ROC-кривой. При пороге срабатывания, равном 1, ни одного ложного срабатывания не будет, поэтому FPR = 0. Однако не будет найдено и ни одного положительного примера, поэтому TPR = 0. 

При пороге срабатывания 0, все положительные примеры будут найдены и TPR = 1, однако это произойдет потому, что все примеры будут классифицированы как положительные и окажется, что FPR = 1.

Польза от модели состоит в том, что вначале чувствительность растет гораздо быстрее, чем доля ложных срабатываний. Затем, по мере уменьшения порога, картина качественно меняется - доля распознавания положительных примеров замедляет рост, а ложные срабатывания увеличиваются. Можно найти компромиссное значение порога, при котором классификатор находит значительную долю положительных примеров, но доля срабатываний не велика.

Для случайного классификатора, распределяющего метки классов без использования информации, содержащейся в переменных-предикторах, ROC - кривая представляет собой наклонную прямую линию, соединяющую точки (0,0) и (1, 1). Такая классификация не дает никакого выигрыша.

Чем сильнее отклоняется ROC-кривая классификатора от этой наклонной прямой линии, тем лучше он работает. В идеале уже при FPR = 0 должно достигаться полное распознавание всех положительных примеров, т.е. ROC-кривая сразу ступенчато увеличивается до TPR = 1. Такое на практике невозможно, однако степень приближения к "идеалу", выраженная площадью под кривой (area under curve, AUC) позволяет количественно судить о качестве работы классификатора. 

Для идеального классификатора AUC = 1. Для бесполезного классификатора AUC = 0.5. Если AUC < 0.5 - модель работает хуже, чем случайный классификатор. Это, как правило, следствие того, что метки классов были перепутаны.

Площадь под кривой можно вычислить с помощью функции `mlr::measureAUC()`, передав ей предсказанные вероятности положительного класса и вектор правильных меток. 

```{r}
measureAUC(probabilities = pr_lr_sexclass, truth = d_test$survived, positive = "survived") * 100
```

Также этот показатель вычисляется в функции `perf()`, созданной нами ранее, если задать вектор вероятностей положительного класса.

```{r}
perf(cl_lr_sexclass_80, d_test$survived, positive = "survived", negative = "died",
     probabilities = pr_lr_sexclass) * 100
```


При интерпретации показателя можно ориентироваться на следующие диапазоны:

- бесполезный классификатор $AUC < 0.6$
- слабый классификатор $0.6 \le AUC < 0.7$
- приемлемый классификатор $0.7 \le AUC < 0.8$
- хороший классификатор $0.8 \le AUC < 0.9$
- очень хороший классификтаор $0.9 \le AUC < 1.0$

Следует учитывать, что эти оценки субъективны. Кроме того, две модели с одинаковой площадью под кривой могут показывать разную эффективность в зависимости от выбранного порога. Поэтому помимо сравнения численных значений показателя принято еще и визуально сравнивать ROC-кривые моделей на одном графике. Ниже будет показано, как это сделать в R.


### Kohen's kappa

Показатель средней точности модели (Accuracy) может приводить к неверным выводам в условиях несбалансированности классов, т.е. когда примеры положительного класса встречаются редко. Рассмотрим, например, случай выявления мошеннических транзакций в банковской системе. Их частота не велика - предположим, что лишь 1 транзакция из 1 миллиона - мошенническая. Если модель классификации будет для всех транзакций выдавать метку класса: "нормальная", то точность такой модели будет практически 100%. Однако она будет бесполезна для выявления мошеннических транзакций. 
Даже случайный "классификатор" будет иметь ненулевую точность, поскольку иногда будет выдавать  ответы, случайно совпадающие с правильными.

Чтобы исключить этот эффект, используется показатель Kohen's kappa, который сопоставляет точность классификатора с точностью случайного классифкатора на тех же данных. При этом случайный классификатор выдает метки классов с вероятностями, равными их относительным частотам в обучающей выборке.

Формула показателя:

$$ \kappa = \frac {ACC - ACC_e} {1 - ACC_e} $$,

где $ACC_e$ - это ожидаемая точность случайного классификатора, которая вычисляется исходя из вероятностей предсказанных и фактических меток классов по формуле:

$$ ACC_e = P(predicted +) \cdot  P(actual +) + P(predicted -) \cdot  P(actual -) $$

Рассчитаем $\kappa$ для нашей модели. Для удобства, преобразуем частоты в таблице ошибок классификации в проценты (от общего количества примеров) с помощью функции `prop.table()`. Тогда, например, вероятность предсказанного положительного класса будет вычисляться как сумма по последней строке таблицы, т.е. TP + FP. 

```{r}
table(predicted = cl_lr_sexclass, actual = d_test$survived) %>% prop.table()
```

Ожидаемая точность случайного классификатора:

```{r}
(0.0954 + 0.2592) * (0.0978 + 0.2592) + (0.5477 + 0.0978) * (0.5477 + 0.0954)
```

Точность, достигнутая моделью:

```{r}
0.5477 + 0.2592
```

Значение $\kappa = 57.9\%$:

```{r}
(0.807 - 0.542) / (1 - 0.542)
```

В R этот показатель вычисляется функцией `mlr::measureKAPPA()`

```{r}
measureKAPPA(truth = d_test$survived, response = cl_lr_sexclass)
```

При интерпретации показателя можно ориентироваться на следующие диапазоны (Landis JR, Koch GG The measurement of obsever agreement for categorical data. Biometrics. 1997; 33:159-174):

- неудовлетворительное согласие $\kappa < 0.2$
- удовлетворительное согласие $0.2 \le \kappa < 0.4$
- умеренное согласие $0.4 \le \kappa < 0.6$
- хорошее согласие $0.6 \le \kappa < 0.8$
- очень хорошее согласие $0.8 \le \kappa < 1.0$


Этот показатель также вычисляется разработанной ранее функцией `perf()`.

## Модель логистической регрессии с двумя факторами

```{r}
cat("Модель логистической регрессии с 2 факторами, порог 0.5:\n")
# Матрица ошибок классификации (confusion matrix)
table(predicted = cl_lr_sexclass, actual = d_test$survived)
perf(cl_lr_sexclass, d_test$survived, 
     positive = "survived", negative = "died",
     probabilities = pr_lr_sexclass) * 100
```


## Модель логистической регрессии с полным набором факторов

```{r}
pr_lr_all <- predict(m_lr_all, newdata = d_test, type = "response")
cl_lr_all <- ifelse(pr_lr_all > 0.5, "survived", "died")

table(predicted = cl_lr_all, actual = d_test$survived)
perf(cl_lr_all, d_test$survived, positive = "survived", negative = "died",
     probabilities = pr_lr_all) * 100
```

При прогнозировании по модели выдается предупреждение. Причина в том, что при ее построении были включены линейно зависимые члены. Т.к. они автоматически исключены, не будем обращать на него внимания.



## Модель логистической регрессии с пошаговым отбором

```{r}
pr_lr_step <- predict(m_lr_step, newdata = d_test, type = "response")
cl_lr_step <- ifelse(pr_lr_step > 0.5, "survived", "died")

table(predicted = cl_lr_step, actual = d_test$survived)
perf(cl_lr_step, d_test$survived, positive = "survived", negative = "died",
     probabilities = pr_lr_step) * 100

```


## Дерево решений rpart (CART)

```{r}
pr_rpart <- predict(m_rpart, newdata = d_test, type = "prob")[, "survived"]
cl_rpart <- predict(m_rpart, newdata = d_test, type = "class")

table(predicted = cl_rpart, actual = d_test$survived)
perf(cl_rpart, d_test$survived, positive = "survived", negative = "died",
     pr_rpart) * 100

```

## Дерево решений ctree

```{r}

pr_ctree <- predict(m_ctree, newdata = d_test, type = "prob") %>% 
  transpose() %>% .[[2]] %>% 
  as.numeric()

cl_ctree <- predict(m_ctree, newdata = d_test, type = "response")

table(predicted = cl_ctree, actual = d_test$survived)
perf(cl_ctree, d_test$survived, positive = "survived", negative = "died",
     probabilities = pr_ctree) * 100

```

## Дерево решений C5.0

```{r}
pr_c50 <- predict(m_c50, newdata = d_test, type = "prob")[, "survived"]
cl_c50 <- predict(m_c50, newdata = d_test, type = "class")

table(predicted = cl_c50, actual = d_test$survived)
perf(cl_c50, d_test$survived, positive = "survived", negative = "died",
     probabilities = pr_c50) * 100
```

## Дерево решений C5.0 с бустингом

```{r}
pr_c50_boost <- predict(m_c50_boost, newdata = d_test, type = "prob")[, "survived"]
cl_c50_boost <- predict(m_c50_boost, newdata = d_test, type = "class")

table(predicted = cl_c50_boost, actual = d_test$survived)
perf(cl_c50_boost, d_test$survived, positive = "survived", negative = "died",
     probabilities = pr_c50_boost) * 100

```


## Сравнение ROC-кривых

По показателю AUC лучшая модель - ансамбль деревьев C5.0 с бустингом (87.5). На втором месте - модель логистической регрессии с пошаговым отбором (87.4) и на третьем - логистическая регрессия с полным набором факторов и взаимодействий (86.9). Сравним вид ROC-кривых для построенных моделей.

Для этого можно использовать пакет `ROCR`. Для построения ROC-кривой необходимо:

 1. С помощью функции `prediction()` и векторов вероятностей положительного класса и фактических меток класса получить объект для оценки точности модели.

 2. С помощью функции `ROCR::performance()` вычислить данные для построения ROC-кривой. Рекомендуем записывать имя этой функции с префиксом пакета `ROCR::`, т.к. функция с таким же именем есть в пакете `mlr` и могут возникать ошибки из-за конфликта имен.
 
 3. Полученный с помощью функции `performance()` объект визуализировать командой `plot()`. 

Вначале покажем, как можно применить этот алгоритм пошагово, т.е. отдельно для каждой модели.


**Вычисление ROC-кривых для каждой модели**

```{r}
perf_lr_sexclass <- prediction(pr_lr_sexclass, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")
perf_lr_all <- prediction(pr_lr_all, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")
perf_lr_step <- prediction(pr_lr_step, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")
perf_rpart <- prediction(pr_rpart, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")
perf_ctree <- prediction(pr_ctree, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")
perf_c50 <- prediction(pr_c50, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")
perf_c50_boost <- prediction(pr_c50_boost, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")

```

**Построение ROC-кривых на одном графике**

Пакет ROCR использует для визуализации средства базовой графики R. При необходимости, можно познакомиться с их использованием [на сайте Rob Kabacoff](http://www.statmethods.net/graphs/index.html). А сравнение ggplot2 и базовой графики с примерами кода для построения графиков приводится в блоге [Flowing Data](http://flowingdata.com/2016/03/22/comparing-ggplot2-and-r-base-graphics/).

```{r}
# Генерация цветовой палитры из 7 элементов (столько у нас моделей):
pal <- RColorBrewer::brewer.pal(7, "Set1") 

# Построение графика первой ROC-кривой
plot(perf_lr_sexclass, col = pal[1], main = "Сравнение моделей")

# Добавление остальных ROC-кривых на тот же график
plot(perf_lr_all, col = pal[2], add = TRUE)
plot(perf_lr_step, col = pal[3], add = TRUE)
plot(perf_rpart, col = pal[4], add = TRUE)
plot(perf_ctree, col = pal[5], add = TRUE)
plot(perf_c50, col = pal[6], add = TRUE)
plot(perf_c50_boost, col = pal[7], add = TRUE)

# Добавление легенды
legend(x = "bottomright",
  legend = 
         c("logistic: sex + class", 
           "logistic: all",
           "logistic: stepwise",
           "rpart",
           "ctree",
           "c5.0",
           "c5.0 + boosting"),
       fill = pal)

```

По графику видно, что хуже всех - модель c5.0. Ее ROC-кривая проходит ниже всех других моделей. Чтобы разобраться в результатах лидеров, построим ROC-кривые трех лучших моделей отдельно.


```{r}
plot(perf_lr_all, col = pal[2])
plot(perf_lr_step, col = pal[3], add = TRUE)
plot(perf_c50_boost, col = pal[7], add = TRUE)

legend(x = "bottomright",
  legend = 
         c("logistic: all",
           "logistic: stepwise",
           "c5.0 + boosting"),
       fill = pal[c(2, 3, 7)])
```

Здесь ситуация неоднозначная. Выбор модели зависит от того, какая доля ложных срабатываний является допустимой. В области низких значений FPR лучше выбрать одну из двух моделей - c5.0 + бустинг или логистическую регрессию без упрощения. В области средних значений FPR (0.4-0.6) лучшая модель - логистическая регрессия с отбором факторов. Если же необходимо выявить практически все положительные примеры (TPR > 90%) ценой увеличения доли ложных срабатываний, то лучшей моделью будет c5.0 + бустинг.

В целом, учитывая, что ROC-кривые строятся по данным выборки и подвержены случайным факторам, следует считать, что все модели демонстрируют близкие результаты и выбирать из них следует используя дополнительные факторы, например простоту интерпретации. По этому показателю предпочтение следует отдать логистической регрессии с отбором факторов. Ансамбль из 20 деревьев представляет собой "черный ящик", а полная модель логистической регрессии сложна в интерпретации, т.к. содержит 26 коэффициентов.


В заключение, покажем, как можно визуализировать ROC-кривые для всех моделей одновременно. Этот способ основан на том, что функция `ROCR::performance()` может вычислять координаты сразу для нескольких ROC-кривых, если предсказанные вероятности положительных классов собрать в одну матрицу с помощью функции `cbind()`. 


```{r}
# Готовим матрицу с прогнозами вероятностей, имя столбца - подпись для легенды
preds <- cbind("logistic: all" = pr_lr_all, 
               "logistic: stepwise" = pr_lr_step,
               "c5.0 + boosting" = pr_c50_boost)
# Заполняем матрицу такой же формы фактическими метками классов
actuals <- matrix(d_test$survived, nrow = nrow(preds), ncol = ncol(preds))

# Считаем данные для ROC-кривой
pred_mat <- ROCR::prediction(preds, actuals)
perf_mat <- ROCR::performance(pred_mat, "tpr", "fpr")

# Рисуем все графики сразу
plot(perf_mat, col = as.list(pal[c(2, 3, 7)])) # Чтобы цвета отображались правильно, нужно преобразовать вектор палитры в список функцией as.list()
legend("bottomright", legend = colnames(preds),
       fill = pal[c(2, 3, 7)])

```

