---
title: "Сравнение моделей классификации"
author: "Заходякин Г.В."
date: '22 апреля 2017 г '
output: 
  html_document: 
    toc: yes
    toc_float: yes
---

# Введение

В этом блокноте содержится пример решения задачи классификации. С помощью методов логистической регресии и дерева решений будут разработаны несколько моделей для предсказания шансов на спасение для пассажиров Титаника. Также рассмотрены подходы к сравнению эффективности и выбору лучшей модели.


# Подготовка

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits = 3) # Точность вывода результатов - 3 значащие цифры
```


```{r, warning=FALSE, message=FALSE}
library(tidyverse) # Манипуляция данными и визуализация
library(forcats) # Работа с факторными переменными
library(party) # Деревья ctree
library(C50) # Деревья C5.0
library(rpart) # Деревья CART
library(rpart.plot) # Визуализация деревьев CART
library(ROCR) # Построение ROC-кривых
library(mlr) # Фреймворк для машинного обучения. Здесь используется для расчета ошибок.
library(RColorBrewer) # Правильные цветовые палитры
library(scales) # Процентный формат для графиков
```

Данные находятся в текстовом файле `titanic.csv`.

```{r, message=FALSE}
d <- read_csv("titanic.csv")
glimpse(d)
```

В наборе данных имеется информация о `r nrow(d)` пассажирах.

Переменные:
 - `survived` - выжил или погиб (целевая переменная)
 - `pclass` - класс (первый, второй или третий)
 - `sex` - пол
 - `age` - возраст, лет
 - `sibsp` - количество сопровождавших пассажира родственников - братьев, сестер или супругов
 - `parch` - количество сопровождавших пассажира детей или родителей
 - `fare` - стоимость билета

Переменные `sibsp`, `parch`, `age` и `fare` - количественные, остальные - категориальные. В данный момент категориальные переменные хранятся как текстовые.

# Разведочный анализ

## Пропуски

Посмотрим на распределение переменных и пропуски.

```{r}
summary(d)
```

В переменных `age` и `fare` есть пропуски. Тариф неизвестен только для одного пассажира, а вот возраст - более чем для 250 пассажиров, т.е. около 20% от общего числа наблюдений. Это много, поэтому если возраст предполагается включить в модель, нужно решить, как быть с пропущенными значениями. Нельзя просто отфильтровать их.

Для моделирования желательно перекодировать текстовые переменные в факторные. Если этого не сделать, то преобразование будет выполнено автоматически при моделировании/визуализации, однако невозможно будет задать удобный порядок уровней фактора.

Преобразуем целевую переменную в фактор:
```{r}
d <- d %>% 
  mutate(survived = as.factor(survived))
```

Уровни фактора будут следовать в алфавитном порядки - `died`, `survived`. Положительным исходом будет считаться последний уровень - `survived`.

## Зависимость выживания пассажира от различных факторов

Посмотрим, как зависит спасение пассажира от различных факторов

### Класс

```{r}
ggplot(d) +
  geom_bar(aes(x = pclass, fill = survived), position = "fill") +
  scale_y_continuous(labels = percent) +
  labs(title = "Вероятность выживания в зависимости от класса",
       x = "Класс пассажира", y = NULL, fill = NULL)
```

Вероятность выживания сильно зависит от класса. В первом классе спаслись более половины пассажиров, в третьем - лишь 25%.

### Пол

```{r}
ggplot(d) + 
  geom_bar(aes(x = sex, fill = survived), position = "fill") +
  scale_y_continuous(labels = percent) +
  labs(title = "Вероятность выживания в зависимости от пола",
       x = "Пол пассажира", y = NULL, fill = NULL)
```

Доля выживших мужчин существенно ниже.

Посмотрим, одинакова ли эта зависимость для пассажиров разных классов.

```{r}
ggplot(d) + 
  geom_bar(aes(x = sex, fill = survived), position = "fill") +
  facet_wrap(~ pclass) + 
  scale_y_continuous(labels = percent) +
  labs(title = "Вероятность выживания в зависимости от пола и класса",
       x = "Пол пассажира", y = NULL, fill = NULL)
```

В первом классе спаслись почти все женщины. Вероятность спасения для мужчин также оказалась вдвое выше, чем для других классов. Во втором классе картина похожая, хотя доля погибших выше. В третьем классе доля погибших наибольшая, причем доли не так сильно различаются в зависимости от пола. Это важный с точки зрения моделирования факт, который означает что влияние фактора "пол" меняется в зависимости от класса и в модель следует включить взаимодействие факторов.

### Возраст

Теперь посмотрим, как вероятность выжить зависит от возраста. Для удобства, разобъем всех пассажиров на возрастные группы по 5 лет.

```{r, fig.height=5, fig.width=10}
ggplot(d) + 
  geom_bar(aes(x = cut(age, breaks = seq(0, 80, by = 5), right = TRUE),
               fill = survived), position = "fill") +
  scale_y_continuous(labels = percent) +
  labs(title = "Вероятность выживания в зависимости от возраста",
       x = "Возраст пассажира", y = NULL, fill = NULL)
```

Зависимость выживания от возраста нелинейная. Видно, что шансы выше для маленьких детей до 5 лет и пожилых людей в возрасте 75 лет и старше. Хотя в интервале 65-75 лет все погибли.
Среди пассажиров, возраст которых неизвестен, доля выживших немного ниже, чем для основной массы пассажиров: по-видимому, неизвестный возраст - следствие того, что пассажир погиб. 

Важно проверить, насколько надежны такие оценки, поэтому построим еще и гистограмму, отражающую количество пассажиров в разных возрастных группах.


```{r}
ggplot(na.omit(d)) + 
  geom_histogram(aes(x = age, fill = survived), bins = 40) +
  labs(title = "Количество выживших и погибших в зависимости от возраста",
       x = "Возраст", y = "Число пассажиров", fill = NULL)
```

Видно что пожилых пассажиров было относительно немного, поэтому не будем обращать внимания на "пик" в диапазоне 75-80 лет.

Теперь посмотрим, различается ли завсимость выживания от возраста в различных классах.

```{r, fig.height=7, fig.width=10}
ggplot(d) + 
  geom_bar(aes(x = cut(age, breaks = seq(0, 80, by = 5), right = TRUE),
               fill = survived), position = "fill") + 
  facet_wrap(~pclass, ncol = 1) +
  scale_y_continuous(labels = percent) +
  labs(title = "Вероятность выживания в зависимости от возраста и класса",
       x = "Возраст пассажира", y = NULL, fill = NULL)  

```

В первом и втором классах почти все дети в возрасте до 15 лет выжили, также видно, что пожилые люди старше 50 лет почти все погибли. При этом снова можно заметить разный характер зависимостей для пассажиров разных классов. Это следует учесть при моделировании.

В логистической регрессии вклад каждого предиктора является линейным. Чтобы корректно передать нелинейность найденной нами зависимости выживания от возраста, создадим факторную переменную. В этом случае каждая группа будет учитываться в модели отдельно.

```{r, fig.height=5, fig.width=10}
d <- d %>%
  mutate(agef = cut(age, 
                    breaks = c(0, 15, 50, 85),
                    labels = c("child", "adult", "senior"),
                    right = FALSE)) %>%
  mutate(agef = fct_explicit_na(agef, na_level = "unknown"))

ggplot(d) + 
  geom_bar(aes(x = agef,
               fill = survived), position = "fill") +
  facet_wrap(~pclass) +
  scale_y_continuous(labels = percent) +
  labs(title = "Вероятность выживания в зависимости от возраста и класса",
       x = "Возрастная категория", y = NULL, fill = NULL)  

```

Очевидна необходимость включения в модель взаимодействия факторов.

### Сопровождающие - братья, сестры и супруги

Посмотрим, как связано с выживанием наличие сопровождающих. Для удобства сделаем переменную категориальной (чтобы столбик соответствовал целому количеству людей).

```{r}
ggplot(d) + 
  geom_bar(aes(x = factor(sibsp),
               fill = survived), position = "fill") +
  scale_y_continuous(labels = percent) +
  labs(title = "Вероятность выживания в зависимости от числа сопровождающих",
       x = "Число братьев, сестер, супругов", y = NULL, fill = NULL)  
  
```

Видно, что наибольшими шансами на выживание обладают пассажиры, следующие с одним или двумя сопровождающими. Для больших групп вероятность резко падает, большие семьи из 6 человек и выше все погибли.

Проверим, одинакова ли эта зависимость для классов.

```{r}

ggplot(d) + 
  geom_bar(aes(x = factor(sibsp),
               fill = survived), position = "fill") + 
  facet_wrap(~pclass, ncol = 1) + 
  scale_y_continuous(labels = percent) +
  labs(title = "Вероятность выживания в зависимости от числа сопровождающих и класса",
       x = "Число братьев, сестер, супругов", y = NULL, fill = NULL)  

```

В целом, характер зависимости похожий для всех классов. В 1 и 2 классах вероятность выживания для групп повышалась, не было очень больших семей. В третьем классе наибольшие шансы выжить были у небольших групп.

Т.к. зависимость выживания от числа сопровождающих нелинейна, разделим пассажиров на категории: одиночки, небольшие группы (1-2 сопровождающих), большие группы (3+ сопровождающих).

```{r, fig.height=5, fig.width=10}
d <- d %>%
  mutate(sibspf = cut(sibsp, 
                      breaks = c(0, 1, 3, 9),
                      labels = c("single", "small","large"),
                      right = FALSE))


ggplot(d) + 
  geom_bar(aes(x = sibspf,
               fill = survived), position = "fill") +
  facet_wrap(~pclass) +
  scale_y_continuous(labels = percent) +
  labs(title = "Вероятность выживания в зависимости от числа сопровождающих и класса",
       x = "Размер группы", y = NULL, fill = NULL)  

```

### Сопровождающие - дети и родители

Аналогичным образом поступим и с количеством сопровождавших пассажира детей или родителей.

Ситуация в целом

```{r}
ggplot(d) + 
  geom_bar(aes(x = factor(parch),
               fill = survived), position = "fill") +
  scale_y_continuous(labels = percent) +
  labs(title = "Вероятность выживания в зависимости от числа сопровождающих",
       x = "Число детей и родителей", y = NULL, fill = NULL)  
```

С учетом классов:

```{r}
ggplot(d) + 
  geom_bar(aes(x = factor(parch),
               fill = survived), position = "fill") +
  facet_wrap(~pclass, ncol = 1) +
  scale_y_continuous(labels = percent) +
  labs(title = "Вероятность выживания в зависимости от числа сопровождающих",
       x = "Число детей и родителей", y = NULL, fill = NULL)  
```

Зависимость такая же, как и для братьев-сестер: у одиночек меньше шансов выжить, небольшая группа повышает их, большие группы погибают с большей вероятностью.

Разделим пассажиров на группы по этому признаку таким же образом, как и в предыдущем случае.

```{r, fig.height=5, fig.width=10}

d <- d %>%
  mutate(parchf = cut(parch, 
                      breaks = c(0, 1, 3, 10),
                      labels = c("single", "small", "large"),
                      right = FALSE))


ggplot(d) + 
  geom_bar(aes(x = parchf,
               fill = survived), position = "fill") +
  facet_wrap(~pclass) +
  scale_y_continuous(labels = percent) +
  labs(title = "Вероятность выживания в зависимости от числа сопровождающих",
       x = "Число детей и родителей", y = NULL, fill = NULL)  

```


### Стоимость билета

Теперь посмотрим, повышает ли более дорогой билет шансы на выживание

```{r}
ggplot(na.omit(d)) + 
  geom_histogram(aes(x = fare, fill = survived), position = "fill", bins = 20) +
  facet_wrap(~pclass, ncol = 1) +
  scale_y_continuous(labels = percent) +
  labs(title = "Вероятность выживания в зависимости от стоимости билета",
       x = "Стоимость билета", y = NULL, fill = NULL)   

```

Зависимость заметна только для 1 и 2 классов. По-видимому, только для них цена (и как следствие - расположение) каюты влияли на шансы спастись. В третьем классе ситуация для всех была одинаково плохой.

Посмотрим, нет ли "скрытого влияния" возраста и пола.

```{r}
ggplot(na.omit(d)) +
  geom_jitter(aes(age, fare, colour = survived)) +
  facet_grid( pclass ~ sex, scale = "free_y")
```

Отличия в тарифах в зависимости от пола не наблюдается. Возраст же связан с тарифом: для детей до 15 лет родители не покупали совсем уж дешевых билетов. Наиболее дешевыми тарифами пользовались врослые люди в 2 и 3-м классах. Их больше всего погибло. Возможно, именно с этим связан рост вероятности выживания в зависимости от тарифа.



# Моделирование 


##  Разделение на обучающую и тестовую выборки

Чтобы реалистично оценить предсказательную силу модели, необходимо проверять ее на новых данных. Для этого разделим список пассажиров на обучающую и тестовые выборки. Чтобы получить воспроизводимый результат, необходимо инициализировать генератор случайных чисел с помощью функции `set.seed()`.

```{r}
set.seed(12) # инициализация генератора случайных чисел
train_ind <- sample(nrow(d), 900)
d_train <- d[train_ind, ] # обучающая выборка
d_test <- d[-train_ind, ] # тестовая выборка
```

## Логистическая регрессия - пол и класс пассажира

Вначале построим логистическую регрессию с двумя наиболее важными факторами - пол и класс пассажира. Вспомним о том, что доли выживших женщин отличались в разных классах, поэтому включим в модель взаимодействие факторов.

```{r}
m_lr_sexclass <- glm(survived ~ pclass + sex + pclass : sex, 
                     data = d_train,
                     family = binomial(link = "logit"))
summary(m_lr_sexclass)
```

### Интерпретация коэффициентов логистической регрессии

Коэффициенты в модели логистической регрессии - это изменение логита, т.е. логарифма шансов при единичном изменении предиктора. В нашей модели все предикторы - это фиктивные переменные, поэтому коэффициенты регрессии показывают отличия в шансах на выживание для соответствующих групп.

Т.к. мы включили пол и класс в модель, коэффициенты позволяют сравнить шансы пассажиров одного и того же пола в разных классах. Или сравнить шансы женщин и мужчин, следовавших одним классом.

Базовой категорией по классу является первый класс. Во втором классе шансы выжить ниже (однако отличие статистически не значимо). В третьем - существенно ниже.

Базовой категорией по полу является женщина. Для мужчин шансы выжить существенно ниже.

Однако, ситуация неодинакова в различных классах. Например, если расмотреть 2 класс, то шансы на выживание мужчин в нем незначительно ниже, а в третьем классе - существенно выше, чем для мужчин в первом классе.

В качестве примера, рассчитаем прогозы.

 - Шансы выжить для женщины из 1 класса: $O = \exp(2.955) = 19.2$  
 Это соответствует вероятности выживания: $P = 19.2 / (19.2 + 1) = 0.95$

 - Шансы выжить для мужчины из 1 класса: $O = \exp(2.955 - 3.409) = 0.635$   
 Вероятность выжить: $P = 0.635 / 1.635 = 0.388$

 - Шансы выжить для мужчины из 2 класса: $O = \exp(2.955 - 0.957 - 3.409 - 0.220) = 0.196$   
 Вероятность выжить: $P = 0.196 / 1.196 = 0.164$

- Шансы выжить для мужчины из 3 класса: $O = \exp(2.955 - 2.916 - 3.409 + 1.717) = 0.191$  
Вероятность выжить: $P = 0.191 / 1.191 = 0.160$

Коэффициенты логистической регрессии, как уже упоминалось, представляют собой изменение логарифма шансов при единичном значении предиктора. Учитывая, что $\ln a - \ln b = \ln a/b$, можно рассматривать угловой коэффициент как логарифм отношения шансов при единичном измении предиктора (0 - нет изменения). Удобнее сравнивать не логарифм, а  само отношение, поэтому можно преобразовать коэффициенты:

```{r}
coefficients(m_lr_sexclass) %>% exp()
```

Теперь сразу видно, что для базовой категории шансы выживания - 19.2, для мужчины из 1 класса шансы выжить ниже (19.2 * 0.0331 = 0.636) и т.д. 

Отношение шансов = 1 означает отсутствие изменения шансов.

В тех случаях, когда результаты исследования получены с помощью случайной выборки и их требуется обобщить на генеральную совокупность, можно воспользоваться расчетом доверительных интервалов для коэффициентов регрессии:

```{r}
confint(m_lr_sexclass) %>% exp()
```

Однако в нашем случае проверка значимости коэффициентов не имеет смысла, т.к. исходные данные не являются случайной выборкой и их не на что обобщить. Тем не менее, можно ориентироваться на показатели значимости, чтобы оценить точность оценки коэффициентов (т.е. сопоставить величину эффекта для группы с ошибкой оценки этого эффекта).


### Альтернативный способ интерпретации модели

Вместо того, чтобы интерпретировать отдельные коэффициенты, можно сделать прогноз по модели для типичных представителей разных категорий и сравить вероятности выживания.

```{r}
nd <- tribble(
  ~pclass, ~sex,
  "1st",   "female",
  "1st",   "male",
  "2nd",   "female",
  "2nd",   "male",
  "3rd",   "female",
  "3rd",   "male"
  )

cbind(nd, prob_survive = predict(m_lr_sexclass, newdata = nd, type = "response"))

```

**Важно:**  поскольку в модели используются факторные переменные, важно чтобы в наборе данных для прогнозирования уровни фактора были такими же, и в том же порядке, что и в наборе, по которому строилась модель. Здесь это достигается благодаря тому, что мы рассмотрели все значения каждого фактора. 


## Логистическая регрессия с сочетанием всех факторов

Теперь построим более сложную регрессию с большим количеством факторов - добавим возрастную категорию и число сопровождающих. Т.к. мы видели, что эти зависимости различные по классам пассажиров, добавим также взаимодействие класса со всеми этими факторами.

```{r}
m_lr_all <- glm(survived ~ (sex + agef + sibspf + parchf + sex) * pclass, 
                data = d_train,
                family = binomial(link = "logit"))
summary(m_lr_all)
```

Модель получилась довольно сложная. Из-за большого числа предикторов увеличились стандартные ошибки оценки коэффициентов, поэтому большинство переменных оказалось незначимыми. Также мы можем наблюдать линейную зависимость между включенными в модель переменными. Один из столбцов - эффект взаимодействия факторов 2 класс и большая группа - был исключен.

## Логистическая регрессия - упрощенная модель 

Попробуем упростить модель, используя метод пошагового исключения переменных. Для выбора лучшей модели функция использует критерий AIC.

```{r}
m_lr_step <- step(m_lr_all)
```

Окончательная модель имеет вид:

```{r}
summary(m_lr_step)
```

В упрощенной модели остались главные эффекты всех факторов. Эффекты взаимодействия учитываются только для пола и класса.

## Дерево решений - rpart

Задачу классификации можно решать и с помощью деревьев решений. Пакет `rpart` в R реализует алгоритм построения деревьев решений CART. 

В отличие от логистической регрессии, деревья решений - локальная модель. Благодаря разделению пространства предикторов на независимые части, внутри которых зависимости могут быть никак не связаны с зависимостями в других частях, для деревьев решений не представляют проблемы нелинейные зависимости, которые мы могли наблюдать в данных: например, что дети и пожилые люди имеют больше шансов выжить, чем люди среднего возраста. В логистической регрессии такие зависимости нужно линеаризовать. В деревьях решений мы можем работать с исходными количественными данными. 

Также алгоритм может работать с пропущенными значениями. Если встречается такое значение в  выбранной для разбиения переменной, то наблюдение классифицируется по другим признакам (surrogate split). Однако имеет смысл пробовать исправлять проблему пропущенных значений явно (например, путем подстановки средних, фиктивных значений или категоризации). Это может улучшить качество модели в некоторых случаях.

```{r}
m_rpart <- rpart(survived ~ pclass + sex + sibsp + parch + age,
                 data = d_train)
rpart.plot(m_rpart)

```

Алгоритм использует различные критерии для предотвращения чрезмерного "разрастания" дерева решения. В данном случае оно получилось довольно "куцым". 

Наиболее важной переменной является пол: по ней проведено разбиение в первую очередь. Дерево, фактически, предсказывает гибель всем мужчинам старше 9 лет. 

Для женщин принятие решения несколько сложнее - учитывается также класс, количество сопровождающих и возраст.  Пороги для разбиения по возрасту несколько отличаются от тех, которые мы подобрали визуальным способом: для детей - 9 лет, для взрослых - 24 года. По числу сопровождающих порог такой же, как и в регрессионной модели, правда он один.

Чистота листьев дерева невысокая. Например, в первом слева листе лишь 80% попавших туда пассажиров в действительности погибли, а в соседнем листе действительно выживших - только 70%. 
В качестве упражненения попытайтесь увеличить "разборчивость" модели, изменяя параметры остановки алгоритма - по числу узлов, числу примеров в узле и параметру сложности `cp`. 
Про это можно почитать в справке - см. `?rpart` и `?rpart.control`.


## Дерево решений - ctree

Попробуем применить другой алгоритм построения дерева решений - conditional inference tree (пакет `party`).

```{r, fig.height=7, fig.width=12}
m_ctree <- ctree(survived ~ factor(pclass) + factor(sex) + age + sibsp + parch,
                 data = d_train)
plot(m_ctree)
```

Построенное дерево несколько более симметрично, чем в случае `rpart`, однако оно тоже небольшое и с "грязными" листьями.

## Дерево решений - C5.0

Попробуем применить еще один алгоритм построения дерева решений - C5.0. Поскольку процедура визуализации дерева не очень хорошо работает с текстовыми переменными, мы выведем структуру построенного дерева в текстовом виде.

```{r}
m_c50 <- C5.0(survived ~ pclass + sex + age + sibsp + parch,
                 data = d_train)
summary(m_c50)
```

Построенное дерево очень похоже на дерево, построенное `rpart`. Отличие состоит только в ветви для классификации женщин-пассажиров 3 класса. Вместо возраста используется число сопровождающих детей и родителей.

Дополнительно построим еще одну модель с помощью этого алгоритма - на этот раз, с использованием бустинга. Судьба пассажира будет прогнозироваться ансамблем из 20 деревьев решений.

```{r}
m_c50_boost <- C5.0(survived ~ pclass + sex + age + sibsp + parch,
                 data = d_train, trials = 20)
summary(m_c50_boost)
```

Было построено 20 моделей. Первоначальную ошибку классификации модели удалось снизить с 19.9% только до 19.3%.


# Сравнение моделей

## Методы оценки качества моделей классификации

Оценить точность классификации можно путем сравнения предсказанных моделью меток классов с фактическими. Только сравнение результатов **на тестовом наборе** данных дает объективную оценку предсказательной силы модели. Использование обучающей выборки для оценки ошибки модели дает чрезмерно оптистичный результат, поскольку многие модели склонны к переобучению.

Рассмотрим различные методы оценки точности классификатора на примере логистической регрессии с двумя факторами.

### Интерпретация матрицы ошибок классификации и показателей точности

Поскольку модель логистической регрессии предсказывает не исход, а вероятность исхода, который считается положительным, необходимо преобразовать вероятность в метку класса путем сравнения с некоторым порогом. Для начала используем порог в 50%

```{r}
# Прогноз вероятности выживания
pr_lr_sexclass <- predict(m_lr_sexclass, newdata = d_test, type = "response")

# Прогноз исхода для пассажира
cat("Порог 0.5:\n")
cl_lr_sexclass <- ifelse(pr_lr_sexclass > 0.5, "survived", "died")

# Матрица ошибок классификации (confusion matrix)
table(predicted = cl_lr_sexclass, actual = d_test$survived)

```

Элементами матрицы ошибок классификации являются:

 - $TN = 224$ - истинноотрицательные примеры (предсказана смерть, умер)
 
 - $TP = 106$ - истинноположительные примеры (предсказано спасение, спасся)
 
 - $FP = 39$ - ложноположительные примеры (предсказано спасение, умер)
 
 - $FN = 40$ - ложноотрицательные примеры (предсказана смерть, спасся)
 
 
Всего в тестовой выборке 409 пассажиров

Используя эту матрицу, можно рассчитать [**показатели ошибки модели**](https://en.wikipedia.org/wiki/Sensitivity_and_specificity):

**Средняя точность** (accuracy) - доля правильно классифицированных примеров:


$$ ACC = \frac{TP  + TN}{TP + TN + FP + FN} = \frac{224+106}{409} = 80.7\% $$
Этот показатель характеризует, как часто модель угадывает правильный ответ.


**Средняя ошибка классификации** (overall error rate, mean misclassification error) - доля ошибочно классифицированных примеров:


$$ MMCE = \frac{FP  + FN}{TP + TN + FP + FN} = \frac{39+40}{409} = 19.3\% $$
Этот показатель характеризует, как часто модель ошибается.

**Чувствительность** (sensitivity, true positive rate, recall) - доля положительных примеров, которые были правильно классифицированы как положительные:

$$ TPR =  \frac{TP}{P} = \frac{TP}{TP + FN} = \frac{106}{106 + 40} = 72.6\% $$
Этот показатель характеризует чувствительность модели при обнаружении положительных примеров. Модель с низкой чувствительностью позволит выявить лишь небольшую часть положительных примеров в данных. Модель с высокой чувствительностью выявит большую часть таких примеров.


**Специфичность** (specificity, true negative rate) - доля отрицательных примеров, которые были правильно классифицированы как отрицательные:

$$ TNR =  \frac{TN}{N} = \frac{TN}{TN + FP} = \frac{224}{224 + 39} = 85.2\% $$
Этот показатель аналогичен чувствительности, но здесь интерес представляют отрицательные примеры, а не положительные.


**Доля ложных срабатываний** (false positive rate, fall-out) - доля неправильно классифицированных отрицательных примеров:

$$ FPR =  \frac{FN}{N} = \frac{FP}{TN + FP} = \frac{39}{224 + 39} = 14.8\% $$
Этот показатель характеризует, какая доля отрицательных примеров будет ошибочно классифицирована как положительные. Если рассмотреть задачу классификации почты на полезную и спам, то "ложным срабатыванием" модели будет попадание полезного письма в спам ("положительным", т.е. интересным классом здесь будет спам, номальные письма будут "отрицательным" классом). Доля ложных срабатываний в данном случае будет долей полезных писем, попавших в спам.

Можно видеть, что $FPR = 1 - TNR$, т.е. 1 - специфичность.


**Точность** (precision, positive predictive value) - надежность классификации положительных примеров, т.е. доля классифицированных как положительные примеров, которые действительно являются положительными

$$ PPV =  \frac{TP}{TP + FP} = \frac{106}{106 + 39} = 73.1\% $$
Возвращаясь к примеру с фильтрацией спама, точность классификатора можно оценить как долю действительно спамерских писем в папке "Спам".

Для удобства расчета показателей ошибки, создадим функцию. На вход ее нужно подать векторы с прогнозными и фактическими метками класса, метки положительного и отрицательного класса. Также можно подать вектор с вероятностями положительного исхода. Вычисление показателей выполняется с помощью функций пакета `mlr`.

```{r}

# Функция для расчета показателей ошибки
perf <- function(predicted, actual, positive, negative,
                 probabilities = NULL ) {
  p <- 
    c(
      Accuracy = measureACC(actual, predicted),
      kappa = measureKAPPA(actual, predicted),
      TPR = measureTPR(actual, predicted, positive = positive),
      TNR = measureTNR(actual, predicted, negative = negative),
      FPR = measureFPR(actual, predicted, negative = negative, positive = positive),      
      PPV = measurePPV(actual, predicted, positive = positive)
  )
  
  if (!is.null(probabilities)) {
    p <- c(p, AUC = measureAUC(probabilities = probabilities, 
                               truth = actual, 
                               negative = negative,
                               positive = positive))
  }
  p
}

```


Выведем еще раз таблицу с ошибками классификации для двухфакторной регрессионной модели и посчитаем показатели эффективности. 

```{r}
# Прогноз исхода для пассажира
cat("Порог 0.5:\n")
cl_lr_sexclass <- ifelse(pr_lr_sexclass > 0.5, "survived", "died")

# Матрица ошибок классификации (confusion matrix)
table(predicted = cl_lr_sexclass, actual = d_test$survived)
perf(cl_lr_sexclass, d_test$survived, positive = "survived", negative = "died") * 100
```


### Зависимость показателей ошибки от порога классификации

Мы произвольным образом выбрали порог по вероятности положительного исхода, предсказанной моделью. Если предсказанная вероятность выживания превысит 50%, то пассажир будет классифицирован как выживший. Однако порог можно менять. Так, если нужно правильно классифицировать больше выживших в реальности пассажиров, то порог можно снизить. Тогда классификатор будет относить к выжившим большее количество пассажиров и число верно "угаданных" выживших увеличится. Однако увеличится и число "ложных срабатываний". 

Наоборот, если нежелательно, чтобы модель предскзывала выживание пассажирам, которые в действительности погибли, то можно снизить порог. Но неизбежно сократится и число верно "угаданных" выживших, т.е. чувствительность модели.

Сравним результаты при разных значениях порога классификации:

```{r}

cat("Порог 0.8:\n")
cl_lr_sexclass_80 <- ifelse(pr_lr_sexclass > 0.8, "survived", "died")
table(predicted = cl_lr_sexclass_80, actual = d_test$survived)
perf(cl_lr_sexclass_80, d_test$survived, positive = "survived", negative = "died") * 100

cat("\nПорог 0.30:\n")
cl_lr_sexclass_30 <- ifelse(pr_lr_sexclass > 0.3, "survived", "died")
table(predicted = cl_lr_sexclass_30, actual = d_test$survived)
perf(cl_lr_sexclass_30, d_test$survived, positive = "survived", negative = "died") * 100


```


### ROC-анализ

Компромисс между чувствительностью модели (TPR) и долей ложных срабатываний (FPR), можно отобразить в с помощью ROC-кривой (Receiver Operating Curve).

```{r}

performance_lr_sexclass <-  
  prediction(pr_lr_sexclass, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")

plot(performance_lr_sexclass, colorize = TRUE,
     main = "ROC для логрегрессии с факторами: пол и класс")

```

На графике видно, что с увеличением порога классификации снижается доля ложных срабатываний, но и чувствительность тоже падает. 

Здесь показан характерный вид ROC-кривой. При пороге срабатывания, равном 1, ни одного ложного срабатывания не будет, поэтому FPR = 0. Однако не будет найдено и ни одного положительного примера, поэтому TPR = 0. 

При пороге срабатывания 0, все положительные примеры будут найдены и TPR = 1, однако это произойдет потому, что все примеры будут классифицированы как положительные и окажется, что FPR = 1.

Польза от модели состоит в том, что вначале чувствительность растет гораздо быстрее, чем доля ложных срабатываний. Затем, по мере уменьшения порога, картина качественно меняется - доля распознавания положительных примеров замедляет рост, а ложные срабатывания увеличиваются. Можно найти компромиссное значение порога, при котором классификатор находит значительную долю положительных примеров, но доля срабатываний не велика.

Для случайного классификатора, распределяющего метки классов без использования информации, содержащейся в переменных-предикторах, ROC - кривая представляет собой наклонную прямую линию, соединяющую точки (0,0) и (1, 1). Такая классификация не дает никакого выигрыша.

Чем сильнее отклоняется ROC-кривая классификатора от этой наклонной прямой линии, тем лучше он работает. В идеале уже при FPR = 0 должно достигаться полное распознавание всех положительных примеров, т.е. ROC-кривая сразу ступенчато увеличивается до TPR = 1. Такое на практике невозможно, однако степень приближения к "идеалу", выраженная площадью под кривой (area under curve, AUC) позволяет количественно судить о качестве работы классификатора. 

Для идеального классификатора AUC = 1. Для бесполезного классификатора AUC = 0.5. Если AUC < 0.5 - модель работает хуже, чем случайный классификатор. Это, как правило, следствие того, что метки классов были перепутаны.

Площадь под кривой можно вычислить с помощью функции `mlr::measureAUC()`, передав ей предсказанные вероятности положительного класса и вектор правильных меток. 

```{r}
measureAUC(probabilities = pr_lr_sexclass, truth = d_test$survived, positive = "survived") * 100
```

Также этот показатель вычисляется в функции `perf()`, созданной нами ранее, если задать вектор вероятностей положительного класса.

```{r}
perf(cl_lr_sexclass_80, d_test$survived, positive = "survived", negative = "died",
     probabilities = pr_lr_sexclass) * 100
```


При интерпретации показателя можно ориентироваться на следующие диапазоны:

- бесполезный классификатор $AUC < 0.6$
- слабый классификатор $0.6 \le AUC < 0.7$
- приемлемый классификатор $0.7 \le AUC < 0.8$
- хороший классификатор $0.8 \le AUC < 0.9$
- очень хороший классификтаор $0.9 \le AUC < 1.0$

Следует учитывать, что эти оценки субъективны. Кроме того, две модели с одинаковой площадью под кривой могут показывать разную эффективность в зависимости от выбранного порога. Поэтому помимо сравнения численных значений показателя принято еще и визуально сравнивать ROC-кривые моделей на одном графике. Ниже будет показано, как это сделать в R.


### Kohen's kappa

Показатель средней точности модели (Accuracy) может приводить к неверным выводам в условиях несбалансированности классов, т.е. когда примеры положительного класса встречаются редко. Рассмотрим, например, случай выявления мошеннических транзакций в банковской системе. Их частота не велика - предположим, что лишь 1 транзакция из 1 миллиона - мошенническая. Если модель классификации будет для всех транзакций выдавать метку класса: "нормальная", то точность такой модели будет практически 100%. Однако она будет бесполезна для выявления мошеннических транзакций. 
Даже случайный "классификатор" будет иметь ненулевую точность, поскольку иногда будет выдавать  ответы, случайно совпадающие с правильными.

Чтобы исключить этот эффект, используется показатель Kohen's kappa, который сопоставляет точность классификатора с точностью случайного классифкатора на тех же данных. При этом случайный классификатор выдает метки классов с вероятностями, равными их относительным частотам в обучающей выборке.

Формула показателя:

$$ \kappa = \frac {ACC - ACC_e} {1 - ACC_e} $$,

где $ACC_e$ - это ожидаемая точность случайного классификатора, которая вычисляется исходя из вероятностей предсказанных и фактических меток классов по формуле:

$$ ACC_e = P(predicted +) \cdot  P(actual +) + P(predicted -) \cdot  P(actual -) $$

Рассчитаем $\kappa$ для нашей модели. Для удобства, преобразуем частоты в таблице ошибок классификации в проценты (от общего количества примеров) с помощью функции `prop.table()`. Тогда, например, вероятность предсказанного положительного класса будет вычисляться как сумма по последней строке таблицы, т.е. TP + FP. 

```{r}
table(predicted = cl_lr_sexclass, actual = d_test$survived) %>% prop.table()
```

Ожидаемая точность случайного классификатора:

```{r}
(0.0954 + 0.2592) * (0.0978 + 0.2592) + (0.5477 + 0.0978) * (0.5477 + 0.0954)
```

Точность, достигнутая моделью:

```{r}
0.5477 + 0.2592
```

Значение $\kappa = 57.9\%$:

```{r}
(0.807 - 0.542) / (1 - 0.542)
```

В R этот показатель вычисляется функцией `mlr::measureKAPPA()`

```{r}
measureKAPPA(truth = d_test$survived, response = cl_lr_sexclass)
```

При интерпретации показателя можно ориентироваться на следующие диапазоны (Landis JR, Koch GG The measurement of obsever agreement for categorical data. Biometrics. 1997; 33:159-174):

- неудовлетворительное согласие $\kappa < 0.2$
- удовлетворительное согласие $0.2 \le \kappa < 0.4$
- умеренное согласие $0.4 \le \kappa < 0.6$
- хорошее согласие $0.6 \le \kappa < 0.8$
- очень хорошее согласие $0.8 \le \kappa < 1.0$


Этот показатель также вычисляется разработанной ранее функцией `perf()`.

## Модель логистической регрессии с двумя факторами

```{r}
cat("Модель логистической регрессии с 2 факторами, порог 0.5:\n")
# Матрица ошибок классификации (confusion matrix)
table(predicted = cl_lr_sexclass, actual = d_test$survived)
perf(cl_lr_sexclass, d_test$survived, 
     positive = "survived", negative = "died",
     probabilities = pr_lr_sexclass) * 100
```


## Модель логистической регрессии с полным набором факторов

```{r}
pr_lr_all <- predict(m_lr_all, newdata = d_test, type = "response")
cl_lr_all <- ifelse(pr_lr_all > 0.5, "survived", "died")

table(predicted = cl_lr_all, actual = d_test$survived)
perf(cl_lr_all, d_test$survived, positive = "survived", negative = "died",
     probabilities = pr_lr_all) * 100
```

При прогнозировании по модели выдается предупреждение. Причина в том, что при ее построении были включены линейно зависимые члены. Т.к. они автоматически исключены, не будем обращать на него внимания.



## Модель логистической регрессии с пошаговым отбором

```{r}
pr_lr_step <- predict(m_lr_step, newdata = d_test, type = "response")
cl_lr_step <- ifelse(pr_lr_step > 0.5, "survived", "died")

table(predicted = cl_lr_step, actual = d_test$survived)
perf(cl_lr_step, d_test$survived, positive = "survived", negative = "died",
     probabilities = pr_lr_step) * 100

```


## Дерево решений rpart (CART)

```{r}
pr_rpart <- predict(m_rpart, newdata = d_test, type = "prob")[, "survived"]
cl_rpart <- predict(m_rpart, newdata = d_test, type = "class")

table(predicted = cl_rpart, actual = d_test$survived)
perf(cl_rpart, d_test$survived, positive = "survived", negative = "died",
     pr_rpart) * 100

```

## Дерево решений ctree

```{r}

pr_ctree <- predict(m_ctree, newdata = d_test, type = "prob") %>% 
  transpose() %>% .[[2]] %>% 
  as.numeric()

cl_ctree <- predict(m_ctree, newdata = d_test, type = "response")

table(predicted = cl_ctree, actual = d_test$survived)
perf(cl_ctree, d_test$survived, positive = "survived", negative = "died",
     probabilities = pr_ctree) * 100

```

## Дерево решений C5.0

```{r}
pr_c50 <- predict(m_c50, newdata = d_test, type = "prob")[, "survived"]
cl_c50 <- predict(m_c50, newdata = d_test, type = "class")

table(predicted = cl_c50, actual = d_test$survived)
perf(cl_c50, d_test$survived, positive = "survived", negative = "died",
     probabilities = pr_c50) * 100
```

## Дерево решений C5.0 с бустингом

```{r}
pr_c50_boost <- predict(m_c50_boost, newdata = d_test, type = "prob")[, "survived"]
cl_c50_boost <- predict(m_c50_boost, newdata = d_test, type = "class")

table(predicted = cl_c50_boost, actual = d_test$survived)
perf(cl_c50_boost, d_test$survived, positive = "survived", negative = "died",
     probabilities = pr_c50_boost) * 100

```


## Сравнение ROC-кривых

По показателю AUC лучшая модель - ансамбль деревьев C5.0 с бустингом (87.5). На втором месте - модель логистической регрессии с пошаговым отбором (87.4) и на третьем - логистическая регрессия с полным набором факторов и взаимодействий (86.9). Сравним вид ROC-кривых для построенных моделей.

Для этого можно использовать пакет `ROCR`. Для построения ROC-кривой необходимо:

 1. С помощью функции `prediction()` и векторов вероятностей положительного класса и фактических меток класса получить объект для оценки точности модели.

 2. С помощью функции `ROCR::performance()` вычислить данные для построения ROC-кривой. Рекомендуем записывать имя этой функции с префиксом пакета `ROCR::`, т.к. функция с таким же именем есть в пакете `mlr` и могут возникать ошибки из-за конфликта имен.
 
 3. Полученный с помощью функции `performance()` объект визуализировать командой `plot()`. 

Вначале покажем, как можно применить этот алгоритм пошагово, т.е. отдельно для каждой модели.


**Вычисление ROC-кривых для каждой модели**

```{r}
perf_lr_sexclass <- prediction(pr_lr_sexclass, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")
perf_lr_all <- prediction(pr_lr_all, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")
perf_lr_step <- prediction(pr_lr_step, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")
perf_rpart <- prediction(pr_rpart, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")
perf_ctree <- prediction(pr_ctree, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")
perf_c50 <- prediction(pr_c50, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")
perf_c50_boost <- prediction(pr_c50_boost, d_test$survived) %>% 
  ROCR::performance("tpr", "fpr")

```

**Построение ROC-кривых на одном графике**

Пакет ROCR использует для визуализации средства базовой графики R. При необходимости, можно познакомиться с их использованием [на сайте Rob Kabacoff](http://www.statmethods.net/graphs/index.html). А сравнение ggplot2 и базовой графики с примерами кода для построения графиков приводится в блоге [Flowing Data](http://flowingdata.com/2016/03/22/comparing-ggplot2-and-r-base-graphics/).

```{r}
# Генерация цветовой палитры из 7 элементов (столько у нас моделей):
pal <- RColorBrewer::brewer.pal(7, "Set1") 

# Построение графика первой ROC-кривой
plot(perf_lr_sexclass, col = pal[1], main = "Сравнение моделей")

# Добавление остальных ROC-кривых на тот же график
plot(perf_lr_all, col = pal[2], add = TRUE)
plot(perf_lr_step, col = pal[3], add = TRUE)
plot(perf_rpart, col = pal[4], add = TRUE)
plot(perf_ctree, col = pal[5], add = TRUE)
plot(perf_c50, col = pal[6], add = TRUE)
plot(perf_c50_boost, col = pal[7], add = TRUE)

# Добавление легенды
legend(x = "bottomright",
  legend = 
         c("logistic: sex + class", 
           "logistic: all",
           "logistic: stepwise",
           "rpart",
           "ctree",
           "c5.0",
           "c5.0 + boosting"),
       fill = pal)

```

По графику видно, что хуже всех - модель c5.0. Ее ROC-кривая проходит ниже всех других моделей. Чтобы разобраться в результатах лидеров, построим ROC-кривые трех лучших моделей отдельно.


```{r}
plot(perf_lr_all, col = pal[2])
plot(perf_lr_step, col = pal[3], add = TRUE)
plot(perf_c50_boost, col = pal[7], add = TRUE)

legend(x = "bottomright",
  legend = 
         c("logistic: all",
           "logistic: stepwise",
           "c5.0 + boosting"),
       fill = pal[c(2, 3, 7)])
```

Здесь ситуация неоднозначная. Выбор модели зависит от того, какая доля ложных срабатываний является допустимой. В области низких значений FPR лучше выбрать одну из двух моделей - c5.0 + бустинг или логистическую регрессию без упрощения. В области средних значений FPR (0.4-0.6) лучшая модель - логистическая регрессия с отбором факторов. Если же необходимо выявить практически все положительные примеры (TPR > 90%) ценой увеличения доли ложных срабатываний, то лучшей моделью будет c5.0 + бустинг.

В целом, учитывая, что ROC-кривые строятся по данным выборки и подвержены случайным факторам, следует считать, что все модели демонстрируют близкие результаты и выбирать из них следует используя дополнительные факторы, например простоту интерпретации. По этому показателю предпочтение следует отдать логистической регрессии с отбором факторов. Ансамбль из 20 деревьев представляет собой "черный ящик", а полная модель логистической регрессии сложна в интерпретации, т.к. содержит 26 коэффициентов.


В заключение, покажем, как можно визуализировать ROC-кривые для всех моделей одновременно. Этот способ основан на том, что функция `ROCR::performance()` может вычислять координаты сразу для нескольких ROC-кривых, если предсказанные вероятности положительных классов собрать в одну матрицу с помощью функции `cbind()`. 


```{r}
# Готовим матрицу с прогнозами вероятностей, имя столбца - подпись для легенды
preds <- cbind("logistic: all" = pr_lr_all, 
               "logistic: stepwise" = pr_lr_step,
               "c5.0 + boosting" = pr_c50_boost)
# Заполняем матрицу такой же формы фактическими метками классов
actuals <- matrix(d_test$survived, nrow = nrow(preds), ncol = ncol(preds))

# Считаем данные для ROC-кривой
pred_mat <- ROCR::prediction(preds, actuals)
perf_mat <- ROCR::performance(pred_mat, "tpr", "fpr")

# Рисуем все графики сразу
plot(perf_mat, col = as.list(pal[c(2, 3, 7)])) # Чтобы цвета отображались правильно, нужно преобразовать вектор палитры в список функцией as.list()
legend("bottomright", legend = colnames(preds),
       fill = pal[c(2, 3, 7)])

```

